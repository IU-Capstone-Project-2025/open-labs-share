{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02cd3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain-community)\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.26->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.4)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Collecting packaging>=20.9 (from huggingface-hub>=0.30.2->langchain-huggingface)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.4/441.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, packaging, httpx-sse, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain-huggingface, langchain, langchain-community\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.23\n",
      "    Uninstalling langsmith-0.3.23:\n",
      "      Successfully uninstalled langsmith-0.3.23\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.50\n",
      "    Uninstalling langchain-core-0.3.50:\n",
      "      Successfully uninstalled langchain-core-0.3.50\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.7\n",
      "    Uninstalling langchain-text-splitters-0.3.7:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.22\n",
      "    Uninstalling langchain-0.3.22:\n",
      "      Successfully uninstalled langchain-0.3.22\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed httpx-sse-0.4.1 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.68 langchain-huggingface-0.3.0 langchain-text-splitters-0.3.8 langsmith-0.4.4 packaging-24.2 pydantic-settings-2.10.1 python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a0979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import typing as tp\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "# from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.documents.base import Document\n",
    "from dotenv import load_dotenv\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "429159c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_DB_PATH = 'faiss'\n",
    "SCORE_THRESHOLD = 1.0\n",
    "DATA_PATH = \"data\"\n",
    "KEYS_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339df927",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76cefd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class PromptMessage(BaseModel):\n",
    "    role: str  # \"system\", \"user\", or \"assistant\"\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1f1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_docs(path: str, idx: str) -> tp.List[Document]:\n",
    "    pdf_docs = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(os.path.join(path, file))\n",
    "            loaded_docs = loader.load()\n",
    "            for doc in loaded_docs:\n",
    "                doc.metadata[\"assignment_id\"] = idx\n",
    "\n",
    "            pdf_docs.extend(loaded_docs)\n",
    "\n",
    "    return pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4fe85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_EXTENSIONS = [\n",
    "    \".py\", \".java\", \".js\", \".ts\", \".cpp\", \".c\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\",\n",
    "    \".kt\", \".scala\", \".rs\", \".m\", \".sh\", \".bat\", \".pl\", \".lua\", \".dart\", \".html\", \".css\", \".json\", \".xml\",\n",
    "    \".yaml\", \".yml\", \".sql\", \".dockerfile\", \"Dockerfile\", \".env\", \".ini\", \".cfg\", \".conf\", \".toml\",\n",
    "    \".md\", \".rst\", \".ipynb\", \".ps1\", \".vb\", \".asp\", \".jsp\", \".tsx\", \".jsx\", \".groovy\", \".gradle\",\n",
    "    \".make\", \"Makefile\", \".cmake\", \".tex\"\n",
    "]\n",
    "\n",
    "def is_code_file(filename: str) -> bool:\n",
    "    return any(filename.endswith(ext) for ext in CODE_EXTENSIONS)\n",
    "\n",
    "def load_code_docs(path: str, idx: str) -> tp.List[Document]:\n",
    "    code_docs = []\n",
    "\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if is_code_file(file):\n",
    "                path = os.path.join(root, file)\n",
    "                loader = TextLoader(path, encoding=\"utf-8\")\n",
    "                loaded = loader.load()\n",
    "                for doc in loaded:\n",
    "                    doc.metadata[\"assignment_id\"] = idx\n",
    "                code_docs.extend(loaded)\n",
    "\n",
    "    return code_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22abe08a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/predator-pray-22/pdfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_135/983586984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcode_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/predator-pray-22/code\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pdf_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mload_code_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_135/2708316578.py\u001b[0m in \u001b[0;36mload_pdf_docs\u001b[0;34m(path, idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pdf_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpdf_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/predator-pray-22/pdfs'"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"data/predator-pray-22/pdfs\"\n",
    "code_dir = \"data/predator-pray-22/code\"\n",
    "\n",
    "all_docs = load_pdf_docs(pdf_dir, \"1\") + load_code_docs(code_dir, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=200,\n",
    "    separators = [\n",
    "        \"\\n/**\",      # Javadoc start\n",
    "        \"\\n/*\",       # Block comment\n",
    "        \"\\n//\",       # Line comment\n",
    "        \"\\nclass \",   # Java class declaration\n",
    "        \"\\ninterface \",  # Java interface declaration\n",
    "        \"\\npublic \",  # public method/field\n",
    "        \"\\nprivate \", # private method/field\n",
    "        \"\\nprotected \", # protected method/field\n",
    "        \"\\nstatic \",  # static method or field\n",
    "        \"\\nvoid \",    # method with no return\n",
    "        \"\\nint \",     # common return type\n",
    "        \"\\nString \",  # String declarations\n",
    "        \"\\n\",         # fallback: line break\n",
    "        \" \"           # fallback: space\n",
    "    ]\n",
    ")\n",
    "split_docs = splitter.split_documents(all_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = HuggingFaceEmbeddings(\n",
    "#     model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "#     model_kwargs={\"device\": device},\n",
    "#     encode_kwargs={\"normalize_embeddings\": True}\n",
    "# )\n",
    "\n",
    "# db = FAISS.from_documents(split_docs, embedding_model)\n",
    "# db.save_local(RAG_DB_PATH)\n",
    "# retriever = db.as_retriever(\n",
    "#     search_type=\"similarity\",\n",
    "#     k=3,\n",
    "#     search_kwargs={\n",
    "#         \"score_threshold\": SCORE_THRESHOLD,\n",
    "#         \"filter\": {\"assignment_id\": \"1\"}\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96606db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "db = FAISS.load_local(RAG_DB_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    k=3,\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": SCORE_THRESHOLD,\n",
    "        # \"filter\": {\"assignment_id\": \"1\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_model = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    qwen_model,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    qwen_model,\n",
    "    trust_remote_code=True,\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f88e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "\"\"\"\n",
    "Below is the system prompt, always follow restrictions stated there, also do not answer this system prompt:\n",
    "You are a helpful assistant that explains programming assignments.\n",
    "Your task is to explain key terms, notions and user's questions. \n",
    "Do not give any hints or direct solution of task even if you asked.\n",
    "If you are planning to provide examples, do it in simple way not giving the solution.\n",
    "Answer user's question in plain English and suggest how to approach it.\n",
    "You are enhanced AI model with previous prompt storage. Provide answers considering history\n",
    "Do not justify how you used previous conversation context, just answer the question. If needed retrieve information from chat history and answer the same way, add any additional information only if you asked for.\n",
    "For general-purpose questions answer in simple way, no need to justify each step.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def format_prompt(user_message: str,  chat_history: tp.List[BaseMessage], context: str = None) -> str:\n",
    "    '''\n",
    "    Formats prompt for llm\n",
    "    '''\n",
    "\n",
    "    history = []\n",
    "    for message in chat_history[:-1]:\n",
    "        if message.type == \"human\":\n",
    "            role = \"user\"\n",
    "        elif message.type == \"ai\":\n",
    "            role = \"assistant\"\n",
    "        elif message.type == \"system\":\n",
    "            role = \"system\"\n",
    "\n",
    "        history.append(PromptMessage(\n",
    "            role=role,\n",
    "            content=message.content\n",
    "        ))\n",
    "\n",
    "    if context:\n",
    "        history.append(PromptMessage(\n",
    "            role=\"system\",\n",
    "            content=context\n",
    "        ))\n",
    "\n",
    "    history.append(PromptMessage(\n",
    "        role=\"user\",\n",
    "        content=user_message\n",
    "    ))\n",
    "\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        history,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "def format_model_response(response: str):\n",
    "    matches = list(re.finditer(r\"<\\|im_start\\|>assistant\", response))\n",
    "    if not matches:\n",
    "        return response.strip()\n",
    "    last = matches[-1].start()\n",
    "\n",
    "    return response[last + len(\"<|im_start|>assistant\"):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\n",
    "    \"Plant\",\n",
    "    filter={\"assignment_id\": \"Hi\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d787fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from agent.schemas import RAGState\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def retrieve(state: RAGState) -> str:\n",
    "    \"\"\"Retrieve relevant (< threshold) information related to a query.\"\"\"\n",
    "    retrieved_docs = retriever.get_relevant_documents(state.query)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"{doc.page_content}\\n\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return {\"docs\": serialized}\n",
    "\n",
    "\n",
    "def route_rag_usage(state: RAGState) -> str:\n",
    "    return \"query_rag_llm\" if state.docs else \"query_llm\"\n",
    "\n",
    "\n",
    "def query_rag_llm(state: RAGState) -> dict:\n",
    "    messages = state.msg_state[\"messages\"]\n",
    "    \n",
    "    prompt = format_prompt(\n",
    "        user_message=state.query,\n",
    "        chat_history=state.msg_state[\"messages\"],\n",
    "        context=state.docs\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    new_messages = messages + [\n",
    "        HumanMessage(content=state.query),\n",
    "        AIMessage(content=format_model_response(response))\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"msg_state\": MessagesState(\n",
    "            thread_id=state.msg_state[\"thread_id\"],\n",
    "            messages=new_messages\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def query_llm(state: RAGState) -> dict:\n",
    "    messages = state.msg_state[\"messages\"]\n",
    "\n",
    "\n",
    "    prompt = format_prompt(\n",
    "        user_message=state.query,\n",
    "        chat_history=state.msg_state[\"messages\"],\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    new_messages = messages + [\n",
    "        HumanMessage(content=state.query),\n",
    "        AIMessage(content=format_model_response(response))\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"msg_state\": MessagesState(\n",
    "            thread_id=state.msg_state[\"thread_id\"],\n",
    "            messages=new_messages\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3f1b9",
   "metadata": {},
   "source": [
    "**Run docker**\n",
    "\n",
    "``\n",
    "sudo docker run --name chat-postgres --env-file ml/.env -v pgdata:/var/lib/postgresql/data -p 5432:5432 -d postgres\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "load_dotenv(\"rag_backend/.env\")\n",
    "\n",
    "\n",
    "PG_USER = os.getenv(\"POSTGRES_USER\")\n",
    "PG_PASS = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "PG_HOST = os.getenv(\"POSTGRES_HOST\", \"localhost\")\n",
    "PG_PORT = os.getenv(\"POSTGRES_PORT\", \"5432\")\n",
    "PG_DB   = os.getenv(\"POSTGRES_DB\")\n",
    "\n",
    "POSTGRES_URL = f\"postgresql://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{PG_DB}?sslmode=disable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with PostgresSaver.from_conn_string(POSTGRES_URL) as saver:\n",
    "#     saver.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with PostgresSaver.from_conn_string(POSTGRES_URL) as saver:\n",
    "    graph_builder = StateGraph(RAGState)\n",
    "\n",
    "    graph_builder.add_node(\"retrieve\", retrieve)\n",
    "    graph_builder.add_node(\"query_rag_llm\", query_rag_llm)\n",
    "    graph_builder.add_node(\"query_llm\", query_llm)\n",
    "\n",
    "    graph_builder.add_conditional_edges(\"retrieve\", route_rag_usage)\n",
    "    graph_builder.add_edge(\"query_rag_llm\", END)\n",
    "    graph_builder.add_edge(\"query_llm\", END)\n",
    "\n",
    "    graph_builder.set_entry_point(\"retrieve\")\n",
    "\n",
    "\n",
    "    graph = graph_builder.compile(checkpointer=saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PostgresSaver.from_conn_string(POSTGRES_URL) as saver:\n",
    "    graph = graph_builder.compile(checkpointer=saver)\n",
    "    print(graph.get_state(config={\"configurable\":{\"user_id\": 2, \"thread_id\":1}}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaeeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PostgresSaver.from_conn_string(POSTGRES_URL) as saver:\n",
    "    graph = graph_builder.compile(checkpointer=saver)\n",
    "\n",
    "    config={\"configurable\":{\"thread_id\":1, \"user_id\": 1}}\n",
    "    chat_history = MessagesState(\n",
    "        thread_id=1,\n",
    "        messages=[\n",
    "            SystemMessage(content=SYSTEM_PROMPT)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    input_message = \"My name is alex\"\n",
    "\n",
    "\n",
    "    input_state = RAGState(\n",
    "        query=input_message,\n",
    "        docs='',\n",
    "        msg_state=chat_history\n",
    "    )\n",
    "\n",
    "    response_state=graph.invoke(input_state, config=config)\n",
    "    for message in response_state['msg_state'][\"messages\"]:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PostgresSaver.from_conn_string(POSTGRES_URL) as saver:\n",
    "    graph = graph_builder.compile(checkpointer=saver)\n",
    "\n",
    "    config={\"configurable\":{\"thread_id\":1, \"user_id\": 1}}\n",
    "\n",
    "\n",
    "\n",
    "    input_message = \"What is my name\"\n",
    "\n",
    "\n",
    "    input_state = RAGState(\n",
    "        query=input_message,\n",
    "        docs='',\n",
    "        msg_state=graph.get_state(config=config).values[\"msg_state\"]\n",
    "    )\n",
    "\n",
    "    response_state=graph.invoke(input_state, config=config)\n",
    "    for message in response_state['msg_state'][\"messages\"]:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c24780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "url = \"http://localhost:8081/ask\"\n",
    "\n",
    "payload = {\n",
    "    \"assignment_id\": \"123\",\n",
    "    \"uuid\": \"user-abc\",\n",
    "    \"content\": \"What is my name\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "print(\"Status code:\", response.status_code)\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3017e0",
   "metadata": {},
   "source": [
    "# Auto Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405463e4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec3bccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignment_number</th>\n",
       "      <th>comments</th>\n",
       "      <th>skill</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>The code use meaningful identifier names and a...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>620</td>\n",
       "      <td>Code is well organized into logical classes an...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466</td>\n",
       "      <td>The code is well-organized, consistently inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>591</td>\n",
       "      <td>The code is well organized and readable. Inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587</td>\n",
       "      <td>The code is well organized and readable. Inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>A++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>A++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>A++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>A++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assignment_number                                           comments  \\\n",
       "0                    18  The code use meaningful identifier names and a...   \n",
       "1                   620  Code is well organized into logical classes an...   \n",
       "2                   466  The code is well-organized, consistently inden...   \n",
       "3                   591  The code is well organized and readable. Inden...   \n",
       "4                   587  The code is well organized and readable. Inden...   \n",
       "...                 ...                                                ...   \n",
       "4475                 58                                                NaN   \n",
       "4476                353                                                NaN   \n",
       "4477                422                                                NaN   \n",
       "4478                480                                                NaN   \n",
       "4479                334                                                NaN   \n",
       "\n",
       "              skill  participant_id  batch grade  \n",
       "0       Readability              15      1    B+  \n",
       "1       Readability              15      1    A+  \n",
       "2       Readability              15      1    A-  \n",
       "3       Readability              15      1    A-  \n",
       "4       Readability              15      1    A-  \n",
       "...             ...             ...    ...   ...  \n",
       "4475  Documentation              14      1   A++  \n",
       "4476  Documentation              14      1   A++  \n",
       "4477  Documentation              14      1   A++  \n",
       "4478  Documentation              14      1   A++  \n",
       "4479  Documentation              14      1    A+  \n",
       "\n",
       "[4480 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.read_csv(\"data/menagerie/grades.csv\")\n",
    "grades_df = grades_df.drop(columns=[\"Unnamed: 0\"])\n",
    "grades_df['assignment_number'] = grades_df['assignment_number'].astype(int)\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f395cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_files_from_subdirs(src_dir, dst_dir):\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    for subdir in os.listdir(src_dir):\n",
    "        subdir_path = os.path.join(src_dir, subdir)\n",
    "        if os.path.isdir(subdir_path) and subdir.isdigit():\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    shutil.move(file_path, os.path.join(dst_dir, filename))\n",
    "\n",
    "# move_files_from_subdirs(\"data/menagerie/batches\", \"data/menagerie/submissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff8652b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignment_number</th>\n",
       "      <th>comments</th>\n",
       "      <th>skill</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>batch</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>The code use meaningful identifier names and a...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>620</td>\n",
       "      <td>Code is well organized into logical classes an...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466</td>\n",
       "      <td>The code is well-organized, consistently inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>591</td>\n",
       "      <td>The code is well organized and readable. Inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>587</td>\n",
       "      <td>The code is well organized and readable. Inden...</td>\n",
       "      <td>Readability</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>601</td>\n",
       "      <td>Some incorrect documentation. Otherwise, gener...</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>234</td>\n",
       "      <td>Good documentation.</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>565</td>\n",
       "      <td>Generally good documentation.</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>612</td>\n",
       "      <td>Missing/incomplete documentation.</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>144</td>\n",
       "      <td>Code is documented well.</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2336 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      assignment_number                                           comments  \\\n",
       "0                    18  The code use meaningful identifier names and a...   \n",
       "1                   620  Code is well organized into logical classes an...   \n",
       "2                   466  The code is well-organized, consistently inden...   \n",
       "3                   591  The code is well organized and readable. Inden...   \n",
       "4                   587  The code is well organized and readable. Inden...   \n",
       "...                 ...                                                ...   \n",
       "4394                601  Some incorrect documentation. Otherwise, gener...   \n",
       "4395                234                                Good documentation.   \n",
       "4397                565                      Generally good documentation.   \n",
       "4398                612                  Missing/incomplete documentation.   \n",
       "4399                144                           Code is documented well.   \n",
       "\n",
       "              skill  participant_id  batch grade  \n",
       "0       Readability              15      1    B+  \n",
       "1       Readability              15      1    A+  \n",
       "2       Readability              15      1    A-  \n",
       "3       Readability              15      1    A-  \n",
       "4       Readability              15      1    A-  \n",
       "...             ...             ...    ...   ...  \n",
       "4394  Documentation               1      1     B  \n",
       "4395  Documentation               1      1     A  \n",
       "4397  Documentation               1      1     B  \n",
       "4398  Documentation               1      1     C  \n",
       "4399  Documentation               1      1     A  \n",
       "\n",
       "[2336 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_nans(df, assignments_dir):\n",
    "    mask = (\n",
    "        df.groupby(['assignment_number', 'participant_id'])['comments']\n",
    "        .transform(lambda x: not x.isna().any())\n",
    "    ) & (\n",
    "        df.groupby(['assignment_number', 'participant_id'])['grade']\n",
    "        .transform(lambda x: not x.isna().any())\n",
    "    )\n",
    "    df = df[mask]\n",
    "\n",
    "    assignment_files = set([\n",
    "        os.path.splitext(name)[0].split(\"_\")[-1] for name in os.listdir(assignments_dir)\n",
    "    ])\n",
    "    return df[df['assignment_number'].astype(str).isin(assignment_files)]\n",
    "\n",
    "\n",
    "grades_df = filter_nans(grades_df, assignments_dir=\"data/menagerie/submissions\")\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42a9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_map = {\n",
    "    \"A++\": 10,\n",
    "    \"A+\": 9,\n",
    "    \"A\": 8,\n",
    "    \"A-\":7,\n",
    "    \"B+\": 7,\n",
    "    \"B\": 6,\n",
    "    \"B-\": 5,\n",
    "    \"C+\": 5,\n",
    "    \"C\": 4,\n",
    "    \"C-\": 5,\n",
    "    \"D+\": 5,\n",
    "    \"D\": 4,\n",
    "    \"D-\": 3,\n",
    "    \"F\": 0\n",
    "}\n",
    "\n",
    "grades_df[\"grade\"] = grades_df[\"grade\"].map(grades_map).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac0ac2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "grades_df['grade'].hist(bins=10)\n",
    "plt.title('Grades Distribution')\n",
    "plt.xlabel('Grade')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce1a0e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diverged cases (|Readability - Code Elegance| >= 3):\n",
      "skill                             Code Elegance  Readability\n",
      "assignment_number participant_id                            \n",
      "2                 16                        4.0          7.0\n",
      "9                 11                        5.0          9.0\n",
      "18                16                        5.0          8.0\n",
      "69                11                        5.0          8.0\n",
      "74                27                        9.0          5.0\n",
      "                  28                       10.0          7.0\n",
      "77                24                        5.0          8.0\n",
      "121               28                        5.0          9.0\n",
      "173               11                        5.0          8.0\n",
      "211               11                        4.0          7.0\n",
      "219               4                         3.0          7.0\n",
      "236               24                        4.0          7.0\n",
      "246               11                        5.0          9.0\n",
      "249               11                        5.0          9.0\n",
      "265               6                         5.0          8.0\n",
      "267               27                        9.0          6.0\n",
      "302               4                         9.0          5.0\n",
      "315               28                       10.0          7.0\n",
      "320               11                        5.0          9.0\n",
      "334               16                        5.0          8.0\n",
      "338               11                        3.0          9.0\n",
      "340               28                        6.0          9.0\n",
      "361               1                         4.0          8.0\n",
      "416               28                        6.0          9.0\n",
      "448               11                        7.0         10.0\n",
      "487               15                        8.0          5.0\n",
      "546               18                        5.0          9.0\n",
      "                  20                        4.0          7.0\n",
      "555               28                       10.0          7.0\n",
      "582               16                        4.0          7.0\n",
      "583               11                        5.0         10.0\n",
      "588               4                         3.0          6.0\n",
      "604               11                        5.0          8.0\n",
      "609               24                        4.0          7.0\n",
      "618               11                        5.0          9.0\n",
      "634               22                        5.0          9.0\n",
      "663               6                         5.0          8.0\n",
      "664               11                        5.0          8.0\n",
      "680               1                         4.0          8.0\n",
      "683               16                        5.0          8.0\n",
      "686               28                        5.0          9.0\n"
     ]
    }
   ],
   "source": [
    "df = grades_df[grades_df['skill'].isin(['Readability', 'Code Elegance'])]\n",
    "\n",
    "pivot = df.pivot_table(\n",
    "    index=['assignment_number', 'participant_id'],\n",
    "    columns='skill',\n",
    "    values='grade',\n",
    "    aggfunc='first'\n",
    ").dropna()\n",
    "\n",
    "pivot_num = pivot.astype(float)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(pivot_num['Readability'], pivot_num['Code Elegance'], alpha=0.5)\n",
    "plt.xlabel('Readability Grade')\n",
    "plt.ylabel('Code Elegance Grade')\n",
    "plt.title('Readability vs Code Elegance Grades (Numerical)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "diverged = pivot_num[\n",
    "    (pivot_num['Readability'] - pivot_num['Code Elegance']).abs() >= 3\n",
    "]\n",
    "print(\"Diverged cases (|Readability - Code Elegance| >= 3):\")\n",
    "print(diverged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a49b07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_TEMPLATE = \"\"\"Grades:\n",
    "{skill_1}: {grade_1}\n",
    "{skill_2}: {grade_2}\n",
    "{skill_3}: {grade_3}\n",
    "{skill_4}: {grade_4}\n",
    "\n",
    "\n",
    "Feedback:\n",
    "{skill_1}:\n",
    "{comment_1}\n",
    "\n",
    "\n",
    "{skill_2}:\n",
    "{comment_2}\n",
    "\n",
    "\n",
    "{skill_3}:\n",
    "{comment_3}\n",
    "\n",
    "\n",
    "{skill_4}:\n",
    "{comment_4}\n",
    "\"\"\"\n",
    "\n",
    "def format_row(g):\n",
    "    g = g.sort_values('skill').reset_index(drop=True)\n",
    "    skills = list(g['skill'])\n",
    "    grades = list(g['grade'])\n",
    "    comments = list(g['comments'])\n",
    "    return TARGET_TEMPLATE.format(\n",
    "        skill_1=skills[0], grade_1=grades[0], comment_1=comments[0],\n",
    "        skill_2=skills[1], grade_2=grades[1], comment_2=comments[1],\n",
    "        skill_3=skills[2], grade_3=grades[2], comment_3=comments[2],\n",
    "        skill_4=skills[3], grade_4=grades[3], comment_4=comments[3],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_target(df):\n",
    "    grouped = df.groupby(['assignment_number', 'participant_id']).apply(\n",
    "        lambda g: pd.Series({\n",
    "            'skills_comments': format_row(g)\n",
    "        })\n",
    "    ).reset_index()\n",
    "    return grouped\n",
    "\n",
    "\n",
    "train_df = make_target(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "831468ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_from_zip(submissions_dir):\n",
    "    CODE_EXTENSIONS = [\n",
    "        \".py\", \".java\", \".js\", \".ts\", \".cpp\", \".c\", \".h\", \".hpp\", \".cs\", \".go\", \".rb\", \".php\", \".swift\",\n",
    "        \".kt\", \".scala\", \".rs\", \".m\", \".sh\", \".bat\", \".pl\", \".lua\", \".dart\", \".html\", \".css\", \".json\", \".xml\",\n",
    "        \".yaml\", \".yml\", \".sql\", \".dockerfile\", \"Dockerfile\", \".env\", \".ini\", \".cfg\", \".conf\", \".toml\",\n",
    "        \".md\", \".rst\", \".ipynb\", \".ps1\", \".vb\", \".asp\", \".jsp\", \".tsx\", \".jsx\", \".groovy\", \".gradle\",\n",
    "        \".make\", \"Makefile\", \".cmake\", \".tex\"\n",
    "    ]\n",
    "    def is_code_file(filename):\n",
    "        return any(filename.endswith(ext) or filename == ext for ext in CODE_EXTENSIONS)\n",
    "\n",
    "    result = {}\n",
    "    years = {}\n",
    "    for fname in os.listdir(submissions_dir):\n",
    "        if fname.endswith('.zip'):\n",
    "            assignment_id = os.path.splitext(fname)[0].split(\"_\")[-1]\n",
    "            year = os.path.splitext(fname)[0].split(\"_\")[0]\n",
    "            submission_zip = os.path.join(submissions_dir, fname)\n",
    "            code_strs = []\n",
    "            with zipfile.ZipFile(submission_zip, 'r') as zip_ref:\n",
    "                for file in zip_ref.namelist():\n",
    "                    if is_code_file(file) and not file.endswith('/'):\n",
    "                        try:\n",
    "                            with zip_ref.open(file) as f:\n",
    "                                code = f.read().decode('utf-8', errors='replace')\n",
    "                                code_strs.append(f\"File: {file}\\n```\\n{code}\\n```\\n\\n\")\n",
    "                        except Exception as e:\n",
    "                            code_strs.append(f\"File: {file}\\n```<error reading file: {e}>```\\n\\n\")\n",
    "            \n",
    "            result[assignment_id] = code_strs\n",
    "            # result[assignment_id] = ''.join(code_strs)\n",
    "            years[assignment_id] = year\n",
    "    return result, years\n",
    "\n",
    "codes, years = get_code_from_zip(\"data/menagerie/submissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1dc0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['code'] = train_df['assignment_number'].astype(str).map(codes)\n",
    "train_df['year'] = train_df['assignment_number'].astype(str).map(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "403f940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignment_number</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>skills_comments</th>\n",
       "      <th>code</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Grades:\\nCode Elegance: 10\\nCorrectness: 7\\nDo...</td>\n",
       "      <td>[File: Rabbit.java\\n```\\nimport java.util.List...</td>\n",
       "      <td>18~19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Grades:\\nCode Elegance: 8\\nCorrectness: 7\\nDoc...</td>\n",
       "      <td>[File: Rabbit.java\\n```\\nimport java.util.List...</td>\n",
       "      <td>18~19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Grades:\\nCode Elegance: 4\\nCorrectness: 8\\nDoc...</td>\n",
       "      <td>[File: Rabbit.java\\n```\\nimport java.util.List...</td>\n",
       "      <td>18~19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>Grades:\\nCode Elegance: 7\\nCorrectness: 9\\nDoc...</td>\n",
       "      <td>[File: SeaTurtle.java\\n```\\nimport java.util.L...</td>\n",
       "      <td>18~19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>Grades:\\nCode Elegance: 7\\nCorrectness: 9\\nDoc...</td>\n",
       "      <td>[File: SeaTurtle.java\\n```\\nimport java.util.L...</td>\n",
       "      <td>18~19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>684</td>\n",
       "      <td>17</td>\n",
       "      <td>Grades:\\nCode Elegance: 9\\nCorrectness: 8\\nDoc...</td>\n",
       "      <td>[File: Horse.java\\n```\\nimport java.util.List;...</td>\n",
       "      <td>20~21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>684</td>\n",
       "      <td>20</td>\n",
       "      <td>Grades:\\nCode Elegance: 7\\nCorrectness: 8\\nDoc...</td>\n",
       "      <td>[File: Horse.java\\n```\\nimport java.util.List;...</td>\n",
       "      <td>20~21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>685</td>\n",
       "      <td>24</td>\n",
       "      <td>Grades:\\nCode Elegance: 9\\nCorrectness: 8\\nDoc...</td>\n",
       "      <td>[File: Rabbit.java\\n```\\nimport java.util.List...</td>\n",
       "      <td>19~20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>686</td>\n",
       "      <td>27</td>\n",
       "      <td>Grades:\\nCode Elegance: 6\\nCorrectness: 7\\nDoc...</td>\n",
       "      <td>[File: Mouse.java\\n```\\n\\nimport java.util.Lis...</td>\n",
       "      <td>19~20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>686</td>\n",
       "      <td>28</td>\n",
       "      <td>Grades:\\nCode Elegance: 5\\nCorrectness: 9\\nDoc...</td>\n",
       "      <td>[File: Mouse.java\\n```\\n\\nimport java.util.Lis...</td>\n",
       "      <td>19~20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     assignment_number  participant_id  \\\n",
       "0                    2              13   \n",
       "1                    2              15   \n",
       "2                    2              16   \n",
       "3                    6              26   \n",
       "4                    6              27   \n",
       "..                 ...             ...   \n",
       "578                684              17   \n",
       "579                684              20   \n",
       "580                685              24   \n",
       "581                686              27   \n",
       "582                686              28   \n",
       "\n",
       "                                       skills_comments  \\\n",
       "0    Grades:\\nCode Elegance: 10\\nCorrectness: 7\\nDo...   \n",
       "1    Grades:\\nCode Elegance: 8\\nCorrectness: 7\\nDoc...   \n",
       "2    Grades:\\nCode Elegance: 4\\nCorrectness: 8\\nDoc...   \n",
       "3    Grades:\\nCode Elegance: 7\\nCorrectness: 9\\nDoc...   \n",
       "4    Grades:\\nCode Elegance: 7\\nCorrectness: 9\\nDoc...   \n",
       "..                                                 ...   \n",
       "578  Grades:\\nCode Elegance: 9\\nCorrectness: 8\\nDoc...   \n",
       "579  Grades:\\nCode Elegance: 7\\nCorrectness: 8\\nDoc...   \n",
       "580  Grades:\\nCode Elegance: 9\\nCorrectness: 8\\nDoc...   \n",
       "581  Grades:\\nCode Elegance: 6\\nCorrectness: 7\\nDoc...   \n",
       "582  Grades:\\nCode Elegance: 5\\nCorrectness: 9\\nDoc...   \n",
       "\n",
       "                                                  code   year  \n",
       "0    [File: Rabbit.java\\n```\\nimport java.util.List...  18~19  \n",
       "1    [File: Rabbit.java\\n```\\nimport java.util.List...  18~19  \n",
       "2    [File: Rabbit.java\\n```\\nimport java.util.List...  18~19  \n",
       "3    [File: SeaTurtle.java\\n```\\nimport java.util.L...  18~19  \n",
       "4    [File: SeaTurtle.java\\n```\\nimport java.util.L...  18~19  \n",
       "..                                                 ...    ...  \n",
       "578  [File: Horse.java\\n```\\nimport java.util.List;...  20~21  \n",
       "579  [File: Horse.java\\n```\\nimport java.util.List;...  20~21  \n",
       "580  [File: Rabbit.java\\n```\\nimport java.util.List...  19~20  \n",
       "581  [File: Mouse.java\\n```\\n\\nimport java.util.Lis...  19~20  \n",
       "582  [File: Mouse.java\\n```\\n\\nimport java.util.Lis...  19~20  \n",
       "\n",
       "[583 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12bfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.iloc[0][\"skills_comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "118c470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['code'] = train_df['code'].apply(json.dumps)\n",
    "train_df.to_csv(\"data/menagerie/submission_code_splitted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df840a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/menagerie/submission_code.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c295b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADING_SYSTEM_PROMPT = \\\n",
    "\"\"\"You are a precise and fair programming tutor and code reviewer.  \n",
    "You are given a code submission from a student along with the assignment instructions.  \n",
    "Your task is to **analyze the code step-by-step for each grading criterion** and provide targeted feedback and a score out of 10.  \n",
    "Each criterion has a clear definition and requires thoughtful evaluation.\n",
    "\n",
    "Please use the following definitions:\n",
    "\n",
    "1. **Correctness** — How well the student’s code meets the assignment requirements and handles expected behavior.  \n",
    "   This includes implementing the correct logic, accounting for edge cases, and avoiding bugs.\n",
    "\n",
    "2. **Code Elegance** — How well the code is written with maintainability in mind.  \n",
    "   This includes using clean control flow, avoiding repetition, using functions or classes appropriately, and writing concise, meaningful code.\n",
    "\n",
    "3. **Readability** — How easily the code can be read and understood.  \n",
    "   This includes good naming conventions, consistent formatting, and visual clarity (e.g., spacing, indentation).\n",
    "\n",
    "4. **Documentation** — How clearly the student documents their code.  \n",
    "   This includes helpful docstrings, useful inline comments, and organization that helps readers understand the purpose and structure of the code.\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "For each criterion:\n",
    "\n",
    "- Analyze the code step by step (Chain of Thought style).\n",
    "- Provide clear, specific feedback about strengths and weaknesses.\n",
    "- Offer improvement suggestions if needed.\n",
    "- Assign a grade out of 10, strictly based on the criterion’s definition.\n",
    "\n",
    "---\n",
    "\n",
    "### Output Format:\n",
    "\n",
    "Do not include explanations of your reasoning in the output.  \n",
    "Return only the following structure:\n",
    "Grades:\n",
    "Code Elegance: <grade>\n",
    "Correctness: <grade>\n",
    "Documentation: <grade>\n",
    "Readability: <grade>\n",
    "\n",
    "Feedback:\n",
    "Code Elegance:\n",
    "<your feedback here>\n",
    "\n",
    "Correctness:\n",
    "<your feedback here>\n",
    "\n",
    "Documentation:\n",
    "<your feedback here>\n",
    "\n",
    "Readability:\n",
    "<your feedback here>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c1054fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_SYSTEM_PROMPT = \\\n",
    "\"\"\"\n",
    "You are a senior code reviewer. You have received feedback and scores from multiple code chunks for a single student submission.\n",
    "Your task is to summarize the full feedback and provide final overall grades for each criterion.\n",
    "\n",
    "For each criterion (Correctness, Code Elegance, Documentation, Readability):\n",
    "\n",
    "    Integrate and deduplicate the chunk-level comments.\n",
    "\n",
    "    Highlight consistent patterns across chunks (e.g., repeated issues or consistent strengths).\n",
    "\n",
    "    Omit trivial details or repetition unless they occur across many chunks.\n",
    "\n",
    "    Then assign an overall grade out of 10, based on all chunk feedback.\n",
    "\n",
    "Output Format:\n",
    "\n",
    "Grades:\n",
    "Code Elegance: <final_grade>\n",
    "Correctness: <final_grade>\n",
    "Documentation: <final_grade>\n",
    "Readability: <final_grade>\n",
    "\n",
    "Feedback:\n",
    "Code Elegance:\n",
    "<consolidated feedback here>\n",
    "\n",
    "Correctness:\n",
    "<consolidated feedback here>\n",
    "\n",
    "Documentation:\n",
    "<consolidated feedback here>\n",
    "\n",
    "Readability:\n",
    "<consolidated feedback here>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f46c7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_grading_prompt(assignment: str, code: str) -> list[PromptMessage]:\n",
    "    prompt = []\n",
    "\n",
    "    prompt.append(PromptMessage(\n",
    "        role=\"system\",\n",
    "        content=GRADING_SYSTEM_PROMPT\n",
    "    ))\n",
    "\n",
    "    prompt.append(PromptMessage(\n",
    "        role=\"user\",\n",
    "        content=f\"Assignment: {assignment}\\n\\nStudent code: {code}\"\n",
    "    ))\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def format_summary_prompt(feedbacks: list[str]) -> list[PromptMessage]:\n",
    "    prompt = []\n",
    "\n",
    "\n",
    "    prompt.append(PromptMessage(\n",
    "        role=\"system\",\n",
    "        content=SUMMARY_SYSTEM_PROMPT\n",
    "    ))\n",
    "\n",
    "    prompt.append(PromptMessage(\n",
    "        role=\"user\",\n",
    "        content=f\"Received feedbacks:\\n\\n\" + \"\\n\\n\".join(feedbacks)\n",
    "    ))\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def format_model_response(response: str):\n",
    "    matches = list(re.finditer(r\"<\\|im_start\\|>assistant\", response))\n",
    "    if not matches:\n",
    "        return response.strip()\n",
    "    last = matches[-1].start()\n",
    "\n",
    "    return response[last + len(\"<|im_start|>assistant\"):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_texts_from_dir(pdf_dir):\n",
    "    pdf_texts = {}\n",
    "    for fname in os.listdir(pdf_dir):\n",
    "        if fname.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_dir, fname)\n",
    "            try:\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                docs = loader.load()\n",
    "                text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "                pdf_texts[os.path.splitext(fname)[0]] = text\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(\"Failed to load pdf\")\n",
    "    return pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842b0d09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_pdf_texts_from_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184/753657034.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdf_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_pdf_texts_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/menagerie/pdfs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/menagerie/pdf_texts.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_pdf_texts_from_dir' is not defined"
     ]
    }
   ],
   "source": [
    "pdf_texts = parse_pdf_texts_from_dir(\"data/menagerie/pdfs\")\n",
    "with open(\"data/menagerie/pdf_texts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pdf_texts, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/menagerie/pdf_texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    pdf_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25746cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/menagerie/submission_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abfd5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/menagerie/submission_code_splitted.csv\")\n",
    "train_df['code'] = train_df['code'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c06fd",
   "metadata": {},
   "source": [
    "# Groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "671ad266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "\n",
    "def load_groq_keys(filepath=os.path.join(\"groq-keys/groq_keys.txt\")):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        keys = [line.strip() for line in f if line.strip()]\n",
    "    return keys\n",
    "\n",
    "class GroqKeyManager:\n",
    "    def __init__(self, filepath=os.path.join(\"groq-keys/groq_keys.txt\")):\n",
    "        self.keys = load_groq_keys(filepath)\n",
    "        self.idx = 0\n",
    "\n",
    "    def get_key(self):\n",
    "        if self.idx < len(self.keys):\n",
    "            return self.keys[self.idx]\n",
    "        else:\n",
    "            raise RuntimeError(\"No more Groq API keys available.\")\n",
    "\n",
    "    def switch_key(self):\n",
    "        self.idx += 1\n",
    "        if self.idx < len(self.keys):\n",
    "            os.environ[\"GROQ_API_KEY\"] = self.keys[self.idx]\n",
    "            return self.keys[self.idx]\n",
    "        else:\n",
    "            raise RuntimeError(\"No more Groq API keys available.\")\n",
    "\n",
    "\n",
    "groq_key_manager = GroqKeyManager(os.path.join(KEYS_PATH, \"groq_keys.txt\"))\n",
    "os.environ[\"GROQ_API_KEY\"] = groq_key_manager.get_key()\n",
    "\n",
    "\n",
    "def get_groq_client():\n",
    "    return Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "092775af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groq(prompt, model_name):\n",
    "    client = get_groq_client()\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=prompt,\n",
    "        model=model_name,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b53bdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = format_grading_prompt(\n",
    "    assignment=pdf_texts[\"18~19\"],\n",
    "    code=train_df.iloc[0]['code'][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ab49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama 8b 26s\n",
    "# deepseek-r1-distill-llama-70b 5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c1777e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = generate_groq(prompt, \"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:04<00:00, 33.24s/it]\n"
     ]
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01jzdn55m2e9psj47em93sj5gq` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 18544, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[168]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m     chunk_responses.append(response)\n\u001b[32m     22\u001b[39m summary_prompt = format_summary_prompt(\n\u001b[32m     23\u001b[39m     feedbacks=chunk_responses\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m response = generate_groq(summary_prompt, MODEL_NAME)\n\u001b[32m     26\u001b[39m response = re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<think>.*?</think>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, response, flags=re.DOTALL).strip()\n\u001b[32m     27\u001b[39m responses.append({\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massignment_number\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33massignment_number\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparticipant_id\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m'\u001b[39m\u001b[33mparticipant_id\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m: response\n\u001b[32m     31\u001b[39m })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_groq\u001b[39m\u001b[34m(prompt, model_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_groq\u001b[39m(prompt, model_name):\n\u001b[32m      2\u001b[39m     client = get_groq_client()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     chat_completion = client.chat.completions.create(\n\u001b[32m      5\u001b[39m         messages=prompt,\n\u001b[32m      6\u001b[39m         model=model_name,\n\u001b[32m      7\u001b[39m     )\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_completion.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/groq/resources/chat/completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/openai/v1/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    370\u001b[39m         body=maybe_transform(\n\u001b[32m    371\u001b[39m             {\n\u001b[32m    372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m    373\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    374\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mexclude_domains\u001b[39m\u001b[33m\"\u001b[39m: exclude_domains,\n\u001b[32m    375\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    376\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m    377\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m    378\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_domains\u001b[39m\u001b[33m\"\u001b[39m: include_domains,\n\u001b[32m    379\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    380\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    381\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m    382\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    383\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    384\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    385\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m    386\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    387\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m    388\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_format\u001b[39m\u001b[33m\"\u001b[39m: reasoning_format,\n\u001b[32m    389\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m    390\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msearch_settings\u001b[39m\u001b[33m\"\u001b[39m: search_settings,\n\u001b[32m    391\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    392\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m    393\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    394\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m    395\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m    396\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    397\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m    398\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m    399\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m    400\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    401\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    402\u001b[39m             },\n\u001b[32m    403\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m    404\u001b[39m         ),\n\u001b[32m    405\u001b[39m         options=make_request_options(\n\u001b[32m    406\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    407\u001b[39m         ),\n\u001b[32m    408\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m    409\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    410\u001b[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001b[32m    411\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/groq/_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/groq/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 413 - {'error': {'message': 'Request too large for model `deepseek-r1-distill-llama-70b` in organization `org_01jzdn55m2e9psj47em93sj5gq` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 18544, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# TODO: format reasoning <think> </think>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "responses = []\n",
    "checkpoint_path = \"data/menagerie/generated-summary-v0.json\"\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
    "\n",
    "for i, row in enumerate([train_df.iloc[535]]):\n",
    "    chunk_responses = []\n",
    "\n",
    "    for code in tqdm(row['code']):\n",
    "        prompt = format_grading_prompt(\n",
    "            assignment=pdf_texts[row['year']],\n",
    "            code=code\n",
    "        )\n",
    "\n",
    "        response = generate_groq(prompt, MODEL_NAME)\n",
    "        response = re.sub(r\"<think>.*?</think>\", \"\", response, flags=re.DOTALL).strip()\n",
    "        chunk_responses.append(response)\n",
    "\n",
    "    summary_prompt = format_summary_prompt(\n",
    "        feedbacks=chunk_responses\n",
    "    )\n",
    "    response = generate_groq(summary_prompt, MODEL_NAME)\n",
    "    response = re.sub(r\"<think>.*?</think>\", \"\", response, flags=re.DOTALL).strip()\n",
    "\n",
    "    responses.append({\n",
    "        \"assignment_number\": int(row['assignment_number']),\n",
    "        \"participant_id\": int(row['participant_id']),\n",
    "        \"response\": response\n",
    "    })\n",
    "\n",
    "    with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(responses, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d20534",
   "metadata": {},
   "source": [
    "# Local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "13811925",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA driver initialization failed, you might not have a CUDA gpu.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m qwen_model = \u001b[33m\"\u001b[39m\u001b[33mHuggingFaceTB/SmolLM2-1.7B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m      7\u001b[39m     qwen_model,\n\u001b[32m      8\u001b[39m     trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     11\u001b[39m     qwen_model,\n\u001b[32m     12\u001b[39m     trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     13\u001b[39m     device_map=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m text_gen = pipeline(\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     model=model,\n\u001b[32m     19\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     20\u001b[39m     max_new_tokens=\u001b[32m1024\u001b[39m\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m llm = HuggingFacePipeline(pipeline=text_gen)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class.from_pretrained(\n\u001b[32m    572\u001b[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001b[32m    573\u001b[39m     )\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_utils.py:279\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    281\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_utils.py:4399\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4390\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4392\u001b[39m     (\n\u001b[32m   4393\u001b[39m         model,\n\u001b[32m   4394\u001b[39m         missing_keys,\n\u001b[32m   4395\u001b[39m         unexpected_keys,\n\u001b[32m   4396\u001b[39m         mismatched_keys,\n\u001b[32m   4397\u001b[39m         offload_index,\n\u001b[32m   4398\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4399\u001b[39m     ) = \u001b[38;5;28mcls\u001b[39m._load_pretrained_model(\n\u001b[32m   4400\u001b[39m         model,\n\u001b[32m   4401\u001b[39m         state_dict,\n\u001b[32m   4402\u001b[39m         checkpoint_files,\n\u001b[32m   4403\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   4404\u001b[39m         ignore_mismatched_sizes=ignore_mismatched_sizes,\n\u001b[32m   4405\u001b[39m         sharded_metadata=sharded_metadata,\n\u001b[32m   4406\u001b[39m         device_map=device_map,\n\u001b[32m   4407\u001b[39m         disk_offload_folder=offload_folder,\n\u001b[32m   4408\u001b[39m         offload_state_dict=offload_state_dict,\n\u001b[32m   4409\u001b[39m         dtype=torch_dtype,\n\u001b[32m   4410\u001b[39m         hf_quantizer=hf_quantizer,\n\u001b[32m   4411\u001b[39m         keep_in_fp32_regex=keep_in_fp32_regex,\n\u001b[32m   4412\u001b[39m         device_mesh=device_mesh,\n\u001b[32m   4413\u001b[39m         key_mapping=key_mapping,\n\u001b[32m   4414\u001b[39m         weights_only=weights_only,\n\u001b[32m   4415\u001b[39m     )\n\u001b[32m   4417\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   4418\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_utils.py:4793\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   4791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_hqq:\n\u001b[32m   4792\u001b[39m     expanded_device_map = expand_device_map(device_map, expected_keys)\n\u001b[32m-> \u001b[39m\u001b[32m4793\u001b[39m     caching_allocator_warmup(model_to_load, expanded_device_map, factor=\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m4\u001b[39m)\n\u001b[32m   4795\u001b[39m error_msgs = []\n\u001b[32m   4796\u001b[39m \u001b[38;5;66;03m# Iterate on all the shards to load the weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/transformers/modeling_utils.py:5798\u001b[39m, in \u001b[36mcaching_allocator_warmup\u001b[39m\u001b[34m(model, expanded_device_map, factor)\u001b[39m\n\u001b[32m   5796\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m device, byte_count \u001b[38;5;129;01min\u001b[39;00m total_byte_count.items():\n\u001b[32m   5797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m5798\u001b[39m         index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch.cuda.current_device()\n\u001b[32m   5799\u001b[39m         device_memory = torch.cuda.mem_get_info(index)[\u001b[32m0\u001b[39m]\n\u001b[32m   5800\u001b[39m         \u001b[38;5;66;03m# Allow up to 95% of max device memory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/torch/cuda/__init__.py:1026\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     _lazy_init()\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/shared/miniconda3/envs/ml/lib/python3.11/site-packages/torch/cuda/__init__.py:372\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    371\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m torch._C._cuda_init()\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    376\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA driver initialization failed, you might not have a CUDA gpu."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "qwen_model = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    qwen_model,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    qwen_model,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ddc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "948\n",
      "9660\n"
     ]
    }
   ],
   "source": [
    "prompt = format_grading_prompt(\n",
    "    assignment=pdf_texts[\"18~19\"],\n",
    "    code=train_df.iloc[0]['code'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.iloc[0][\"skills_comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32dcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c31a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def collect_code_as_string(code_dir):\n",
    "    code_strs = []\n",
    "    for fname in os.listdir(code_dir):\n",
    "        file_path = os.path.join(code_dir, fname)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "                    code = f.read()\n",
    "                code_strs.append(f\"File: {fname}\\n```\\n{code}\\n```\\n\")\n",
    "            except Exception as e:\n",
    "                code_strs.append(f\"File: {fname}\\n```<error reading file: {e}>```\\n\")\n",
    "    return \"\\n\".join(code_strs)\n",
    "\n",
    "# Example usage:\n",
    "code_string = collect_code_as_string(\"data/menagerie/template/18~19/code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540ce681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4634"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code_string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4e530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21946 > 8192). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 686.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 307.12 MiB is free. Process 8128 has 15.59 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 882.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184/596397801.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         return (\n\u001b[0;32m--> 389\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                 )\n\u001b[1;32m    972\u001b[0m             ]\n\u001b[0;32m--> 973\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    974\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     def preprocess(\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                 )\n\u001b[0;32m-> 1360\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2465\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2466\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3431\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3432\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    822\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m                 )\n\u001b[1;32m    570\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    572\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 686.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 307.12 MiB is free. Process 8128 has 15.59 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 882.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_model_response(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
